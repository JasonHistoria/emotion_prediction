# main.py - Updated for your exact file structure

import os
import sys
import pandas as pd

# Import from your files
from poetry_emotion_classifier import *
from visualization.attention_maps import *

def simple_setup():
    """Create necessary directories"""
    directories = [
        'results',
        'results/models', 
        'results/models/pretrained',
        'results/models/final_model',
        'results/visualizations',
        'results/reports'
    ]
    
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
    
    print("‚úÖ ÁõÆÂΩïÁªìÊûÑÂ∑≤ÂàõÂª∫")

def check_data_files():
    """Check if required data files exist"""
    required_files = {
        'data/poem_emotions_consolidated.csv': 'Êï¥ÂêàÂêéÁöÑÊÉÖÊÑüÊï∞ÊçÆ',
        'data/unlabeled_poems.txt': 'Êó†Ê†áÁ≠æËØóÊ≠åÊï∞ÊçÆ'
    }
    
    missing_files = []
    existing_files = {}
    
    for file_path, description in required_files.items():
        if os.path.exists(file_path):
            existing_files[file_path] = description
            print(f"‚úÖ ÊâæÂà∞Êñá‰ª∂: {file_path} ({description})")
        else:
            missing_files.append((file_path, description))
            print(f"‚ùå Áº∫Â∞ëÊñá‰ª∂: {file_path} ({description})")
    
    return existing_files, missing_files

def run_quick_demo():
    """Âø´ÈÄüÊºîÁ§∫ - ‰∏çËøõË°åÂÆåÊï¥ËÆ≠ÁªÉ"""
    print("=" * 50)
    print("üöÄ ËØóÊ≠åÊÉÖÊÑüÂàÜÊûêÁ≥ªÁªü - Âø´ÈÄüÊºîÁ§∫")
    print("=" * 50)
    
    # Setup
    simple_setup()
    
    # Check data
    existing_files, missing_files = check_data_files()
    
    if 'data/poem_emotions_consolidated.csv' not in existing_files:
        print("\n‚ùå ÈîôËØØ: Êâæ‰∏çÂà∞‰∏ªË¶ÅÊï∞ÊçÆÊñá‰ª∂")
        print("ËØ∑Á°Æ‰øù data/poem_emotions_consolidated.csv Êñá‰ª∂Â≠òÂú®")
        return None, None
    
    try:
        # Load and analyze data
        print(f"\nüìä Êï∞ÊçÆÂàÜÊûê...")
        df = pd.read_csv('data/poem_emotions_consolidated.csv', encoding='utf-8')
        
        emotion_names = ['ÂìÄ‰º§', 'ÊÄùÂøµ', 'ÊÄ®ÊÅ®', 'ÂñúÊÇ¶']
        
        print(f"üìù ÊÄªËØóÊ≠åÊï∞Èáè: {len(df)}")
        print(f"üé≠ ÊÉÖÊÑüÁ±ªÂà´: {emotion_names}")
        
        print(f"\nüìà ÊÉÖÊÑüÂàÜÂ∏É:")
        for emotion in emotion_names:
            if emotion in df.columns:
                count = df[emotion].sum()
                percentage = (count / len(df)) * 100
                print(f"  {emotion}: {count} È¶ñ ({percentage:.1f}%)")
        
        # Create basic visualization
        print(f"\nüé® ÁîüÊàêÂü∫Á°ÄÂèØËßÜÂåñ...")
        viz = VisualizationTools()
        viz.plot_emotion_distribution(
            df, emotion_names, 
            'results/visualizations/emotion_distribution.png'
        )
        
        # Sample analysis without training
        print(f"\nü§ñ Ê®°ÊãüÊÉÖÊÑüÂàÜÊûêÁ§∫‰æã:")
        sample_poems = [
            "Êò•Ëä±ÁßãÊúà‰ΩïÊó∂‰∫ÜÔºåÂæÄ‰∫ãÁü•Â§öÂ∞ë",
            "Áã¨Âú®ÂºÇ‰π°‰∏∫ÂºÇÂÆ¢ÔºåÊØèÈÄ¢‰Ω≥ËäÇÂÄçÊÄù‰∫≤", 
            "ÊÄíÂèëÂÜ≤ÂÜ†ÔºåÂá≠Ê†èÂ§Ñ",
            "Êò•È£éÂæóÊÑèÈ©¨ËπÑÁñæÔºå‰∏ÄÊó•ÁúãÂ∞ΩÈïøÂÆâËä±"
        ]
        
        for i, poem in enumerate(sample_poems):
            print(f"\n--- Á§∫‰æã {i+1} ---")
            print(f"ËØóÂè•: {poem}")
            # This is just a demo - in real training, these would be model predictions
            print("Ê®°ÊãüÊÉÖÊÑüÈ¢ÑÊµã:")
            if "Êò•Ëä±ÁßãÊúà" in poem:
                print("  ÂìÄ‰º§: 0.85, ÊÄùÂøµ: 0.72")
            elif "ÂºÇ‰π°" in poem:
                print("  ÊÄùÂøµ: 0.91, ÂìÄ‰º§: 0.43")
            elif "ÊÄíÂèëÂÜ≤ÂÜ†" in poem:
                print("  ÊÄ®ÊÅ®: 0.88, ÊÑ§ÊÄí: 0.76")
            else:
                print("  ÂñúÊÇ¶: 0.82, ÊÄùÂøµ: 0.24")
        
        print(f"\n‚úÖ Âø´ÈÄüÊºîÁ§∫ÂÆåÊàê!")
        print("ËøêË°å 'python main.py train' ËøõË°åÂÆåÊï¥Ê®°ÂûãËÆ≠ÁªÉ")
        
        return df, emotion_names
        
    except Exception as e:
        print(f"‚ùå ÊºîÁ§∫ËøáÁ®ã‰∏≠Âá∫Èîô: {str(e)}")
        return None, None

def run_full_training():
    """ÂÆåÊï¥ËÆ≠ÁªÉÊµÅÁ®ã"""
    print("=" * 50)
    print("üöÄ ËØóÊ≠åÊÉÖÊÑüÂàÜÊûêÁ≥ªÁªü - ÂÆåÊï¥ËÆ≠ÁªÉ")
    print("=" * 50)
    
    # Setup
    simple_setup()
    
    # Check data
    existing_files, missing_files = check_data_files()
    
    if 'data/poem_emotions_consolidated.csv' not in existing_files:
        print("\n‚ùå ÈîôËØØ: Êâæ‰∏çÂà∞‰∏ªË¶ÅÊï∞ÊçÆÊñá‰ª∂")
        return None, None
    
    try:
        # Load unlabeled data for pretraining
        unlabeled_texts = []
        if 'data/unlabeled_poems.txt' in existing_files:
            print(f"\nüìö Âä†ËΩΩÊó†Ê†áÁ≠æÊï∞ÊçÆ...")
            with open('data/unlabeled_poems.txt', 'r', encoding='utf-8') as f:
                unlabeled_texts = [line.strip() for line in f if line.strip()]
            print(f"‚úÖ Âä†ËΩΩ‰∫Ü {len(unlabeled_texts)} È¶ñÊó†Ê†áÁ≠æËØóÊ≠å")
        else:
            print(f"\n‚ö†Ô∏è  Êú™ÊâæÂà∞Êó†Ê†áÁ≠æÊï∞ÊçÆÔºåË∑≥ËøáÈ¢ÑËÆ≠ÁªÉÊ≠•È™§")
        
        # Step 1: Optional Pretraining
        pretrained_model_path = 'bert-base-chinese'  # Default
        
        if len(unlabeled_texts) > 100:
            print(f"\nüîß Ê≠•È™§1: È¢ÑËÆ≠ÁªÉÂáÜÂ§á...")
            try:
                pretrainer = PoetryPretrainer()
                # Use simplified pretraining approach
                pretrained_model_path = pretrainer.pretrain_model(
                    unlabeled_texts[:500],  # Use subset for speed
                    output_dir='results/models/pretrained',
                    epochs=2
                )
                print(f"‚úÖ È¢ÑËÆ≠ÁªÉÂáÜÂ§áÂÆåÊàêÔºå‰ΩøÁî®Ê®°Âûã: {pretrained_model_path}")
            except Exception as e:
                print(f"‚ö†Ô∏è  È¢ÑËÆ≠ÁªÉÂ§±Ë¥•: {e}")
                print("Â∞Ü‰ΩøÁî®ÈªòËÆ§BERTÊ®°Âûã")
                pretrained_model_path = 'bert-base-chinese'
        else:
            print(f"\nüîß Ê≠•È™§1: ‰ΩøÁî®È¢ÑËÆ≠ÁªÉBERTÊ®°Âûã...")
            pretrained_model_path = 'bert-base-chinese'
        
        # Step 2: Load labeled data
        print(f"\nüìä Ê≠•È™§2: Âä†ËΩΩÊ†áÊ≥®Êï∞ÊçÆ...")
        trainer = PoetryEmotionTrainer(model_name=pretrained_model_path)
        texts, labels = trainer.load_data('data/poem_emotions_consolidated.csv')
        print(f"‚úÖ Âä†ËΩΩ‰∫Ü {len(texts)} È¶ñÊ†áÊ≥®ËØóÊ≠å")
        
        # Step 3: Prepare datasets
        print(f"\nüîÑ Ê≠•È™§3: ÂáÜÂ§áËÆ≠ÁªÉÊï∞ÊçÆ...")
        train_dataset, val_dataset, test_dataset = trainer.prepare_datasets(texts, labels)
        
        # Step 4: Train model (Use Simple Trainer directly to avoid dependency issues)
        print(f"\nüéØ Ê≠•È™§4: ËÆ≠ÁªÉÊ®°Âûã...")
        print("‚è≥ ËøôÂèØËÉΩÈúÄË¶ÅÂá†ÂàÜÈíü...")
        
        try:
            # Use the simple trainer (more reliable)
            print("üîÑ ‰ΩøÁî®ÁÆÄÂåñËÆ≠ÁªÉÂô®...")
            simple_trainer = SimplePoetryTrainer(
                model_name=pretrained_model_path,
                emotion_names=trainer.emotion_names
            )
            
            trained_model = simple_trainer.train_model(
                train_dataset,
                val_dataset,
                output_dir='results/models/final_model',
                epochs=3,  # Good balance of speed and quality
                batch_size=4,  # Conservative for memory
                learning_rate=2e-5
            )
            
            # Update trainer reference for later use
            trainer.model = simple_trainer.model
            trainer.tokenizer = simple_trainer.tokenizer
            
            print(f"‚úÖ Ê®°ÂûãËÆ≠ÁªÉÂÆåÊàê")
            
        except Exception as e:
            print(f"‚ùå ËÆ≠ÁªÉÂ§±Ë¥•: {e}")
            print("Ë∑≥ËøáËÆ≠ÁªÉÊ≠•È™§Ôºå‰ΩøÁî®ÊºîÁ§∫Ê®°Âºè...")
            return None, None
        
        # Step 5: Evaluate
        print(f"\nüìà Ê≠•È™§5: ËØÑ‰º∞Ê®°Âûã...")
        predictions, true_labels = trainer.evaluate_model(test_dataset)
        
        # Step 6: Generate visualizations
        print(f"\nüé® Ê≠•È™§6: ÁîüÊàêÂèØËßÜÂåñ...")
        viz = VisualizationTools()
        
        # Load data for visualization
        df = pd.read_csv('data/poem_emotions_consolidated.csv', encoding='utf-8')
        
        # Create visualizations
        viz.plot_emotion_distribution(
            df, trainer.emotion_names, 
            'results/visualizations/emotion_distribution.png'
        )
        
        viz.plot_confusion_matrix(
            true_labels, predictions, trainer.emotion_names,
            'results/visualizations/confusion_matrices.png'
        )
        
        print(f"‚úÖ Âü∫Á°ÄÂèØËßÜÂåñÂÆåÊàê")
        
        # Step 7: Model interpretation
        print(f"\nüîç Ê≠•È™§7: Ê®°ÂûãËß£Èáä...")
        interpreter = PoetryInterpreter(trainer.model, trainer.tokenizer, trainer.emotion_names)
        
        # Test samples
        sample_poems = [
            "Êò•Ëä±ÁßãÊúà‰ΩïÊó∂‰∫ÜÔºåÂæÄ‰∫ãÁü•Â§öÂ∞ë",
            "Áã¨Âú®ÂºÇ‰π°‰∏∫ÂºÇÂÆ¢ÔºåÊØèÈÄ¢‰Ω≥ËäÇÂÄçÊÄù‰∫≤", 
            "ÊÄíÂèëÂÜ≤ÂÜ†ÔºåÂá≠Ê†èÂ§Ñ",
            "Êò•È£éÂæóÊÑèÈ©¨ËπÑÁñæÔºå‰∏ÄÊó•ÁúãÂ∞ΩÈïøÂÆâËä±"
        ]
        
        print(f"\nüé≠ ÊÉÖÊÑüÂàÜÊûêÁ§∫‰æã:")
        for i, poem in enumerate(sample_poems):
            print(f"\n--- Á§∫‰æã {i+1} ---")
            print(f"ËØóÂè•: {poem}")
            
            try:
                explanation = interpreter.explain_prediction(poem)
                
                print("ÊÉÖÊÑüÈ¢ÑÊµã:")
                for emotion, score in explanation['predictions'].items():
                    if score > 0.3:  # Only show confident predictions
                        print(f"  {emotion}: {score:.3f}")
                
                print("ÂÖ≥ÈîÆËØçÂàÜÊûê:")
                for emotion, word_importance in explanation['word_importance'].items():
                    if word_importance:
                        top_words = word_importance[:3]
                        print(f"  {emotion}: {[f'{word}({score:.3f})' for word, score in top_words]}")
                        
            except Exception as e:
                print(f"  ‚ö†Ô∏è ÂàÜÊûêÂ§±Ë¥•: {e}")
        
        # Step 8: Create teaching materials
        print(f"\nüéì Ê≠•È™§8: ÁîüÊàêÊïôÂ≠¶ÊùêÊñô...")
        
        try:
            attention_viz = AttentionVisualizer(trainer.model, trainer.tokenizer, trainer.emotion_names)
            
            # Use first sample for demonstration
            sample_poem = sample_poems[0]
            sample_explanation = interpreter.explain_prediction(sample_poem)
            
            # Create attention heatmap
            print("  ÁîüÊàêÊ≥®ÊÑèÂäõÁÉ≠ÂäõÂõæ...")
            attention_viz.create_attention_heatmap(
                sample_poem,
                save_path='results/visualizations/attention_heatmap_demo.png'
            )
            
            # Create emotion radar
            print("  ÁîüÊàêÊÉÖÊÑüÈõ∑ËææÂõæ...")
            attention_viz.create_interactive_emotion_radar(
                sample_explanation['predictions'],
                sample_poem,
                save_path='results/visualizations/emotion_radar_demo.html'
            )
            
            print(f"‚úÖ ÊïôÂ≠¶ÊùêÊñôÁîüÊàêÂÆåÊàê")
            
        except Exception as e:
            print(f"‚ö†Ô∏è ÊïôÂ≠¶ÊùêÊñôÁîüÊàêÈÉ®ÂàÜÂ§±Ë¥•: {e}")
        
        # Final summary
        print(f"\n" + "=" * 50)
        print("üéâ Á≥ªÁªüËÆ≠ÁªÉÂÆåÊàê!")
        print("=" * 50)
        print("üìÅ ÁªìÊûúÊñá‰ª∂‰ΩçÁΩÆ:")
        print("  ü§ñ ËÆ≠ÁªÉÊ®°Âûã: results/models/final_model/")
        print("  üìä ÂèØËßÜÂåñÂõæË°®: results/visualizations/")
        print("  üìà ÊÉÖÊÑüÂàÜÂ∏ÉÂõæ: results/visualizations/emotion_distribution.png")
        print("  üî• Ê≥®ÊÑèÂäõÁÉ≠ÂäõÂõæ: results/visualizations/attention_heatmap_demo.png")
        print("  üéØ ÊÉÖÊÑüÈõ∑ËææÂõæ: results/visualizations/emotion_radar_demo.html")
        print("=" * 50)
        
        return trainer, interpreter
        
    except Exception as e:
        print(f"\n‚ùå ËÆ≠ÁªÉËøáÁ®ã‰∏≠Âá∫Èîô: {str(e)}")
        print("ËØ∑Ê£ÄÊü•Êï∞ÊçÆÊñá‰ª∂Âíå‰æùËµñÊòØÂê¶Ê≠£Á°ÆÂÆâË£Ö")
        return None, None

def main():
    """‰∏ªÂáΩÊï∞"""
    if len(sys.argv) > 1:
        command = sys.argv[1].lower()
        
        if command == 'demo':
            run_quick_demo()
        elif command == 'train':
            run_full_training()
        else:
            print("Áî®Ê≥ï:")
            print("  python main.py demo    # Âø´ÈÄüÊºîÁ§∫")  
            print("  python main.py train   # ÂÆåÊï¥ËÆ≠ÁªÉ")
    else:
        print("üöÄ ËØóÊ≠åÊÉÖÊÑüÂàÜÊûêÁ≥ªÁªü")
        print("\nÈÄâÊã©ËøêË°åÊ®°Âºè:")
        print("1. Âø´ÈÄüÊºîÁ§∫ (‰∏çËÆ≠ÁªÉÊ®°Âûã)")
        print("2. ÂÆåÊï¥ËÆ≠ÁªÉ (ËÆ≠ÁªÉÂπ∂‰øùÂ≠òÊ®°Âûã)")
        
        choice = input("\nËØ∑ËæìÂÖ•ÈÄâÊã© (1 Êàñ 2): ").strip()
        
        if choice == '1':
            run_quick_demo()
        elif choice == '2':
            run_full_training()
        else:
            print("Êó†ÊïàÈÄâÊã©ÔºåËøêË°åÂø´ÈÄüÊºîÁ§∫...")
            run_quick_demo()

if __name__ == "__main__":
    main()