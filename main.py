# main.py - Updated for your exact file structure

import os
import sys
import pandas as pd

# Import from your files
from poetry_emotion_classifier import *
from visualization.attention_maps import *

def simple_setup():
    """Create necessary directories"""
    directories = [
        'results',
        'results/models', 
        'results/models/pretrained',
        'results/models/final_model',
        'results/visualizations',
        'results/reports'
    ]
    
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
    
    print("âœ… ç›®å½•ç»“æ„å·²åˆ›å»º")

def check_data_files():
    """Check if required data files exist"""
    required_files = {
        'data/poem_emotions_consolidated.csv': 'æ•´åˆåçš„æƒ…æ„Ÿæ•°æ®',
        'data/unlabeled_poems.txt': 'æ— æ ‡ç­¾è¯—æ­Œæ•°æ®'
    }
    
    missing_files = []
    existing_files = {}
    
    for file_path, description in required_files.items():
        if os.path.exists(file_path):
            existing_files[file_path] = description
            print(f"âœ… æ‰¾åˆ°æ–‡ä»¶: {file_path} ({description})")
        else:
            missing_files.append((file_path, description))
            print(f"âŒ ç¼ºå°‘æ–‡ä»¶: {file_path} ({description})")
    
    return existing_files, missing_files

def run_quick_demo():
    """å¿«é€Ÿæ¼”ç¤º - ä¸è¿›è¡Œå®Œæ•´è®­ç»ƒ"""
    print("=" * 50)
    print("ğŸš€ è¯—æ­Œæƒ…æ„Ÿåˆ†æç³»ç»Ÿ - å¿«é€Ÿæ¼”ç¤º")
    print("=" * 50)
    
    # Setup
    simple_setup()
    
    # Check data
    existing_files, missing_files = check_data_files()
    
    if 'data/poem_emotions_consolidated.csv' not in existing_files:
        print("\nâŒ é”™è¯¯: æ‰¾ä¸åˆ°ä¸»è¦æ•°æ®æ–‡ä»¶")
        print("è¯·ç¡®ä¿ data/poem_emotions_consolidated.csv æ–‡ä»¶å­˜åœ¨")
        return None, None
    
    try:
        # Load and analyze data
        print(f"\nğŸ“Š æ•°æ®åˆ†æ...")
        df = pd.read_csv('data/poem_emotions_consolidated.csv', encoding='utf-8')
        
        emotion_names = ['å“€ä¼¤', 'æ€å¿µ', 'æ€¨æ¨', 'å–œæ‚¦']
        
        print(f"ğŸ“ æ€»è¯—æ­Œæ•°é‡: {len(df)}")
        print(f"ğŸ­ æƒ…æ„Ÿç±»åˆ«: {emotion_names}")
        
        print(f"\nğŸ“ˆ æƒ…æ„Ÿåˆ†å¸ƒ:")
        for emotion in emotion_names:
            if emotion in df.columns:
                count = df[emotion].sum()
                percentage = (count / len(df)) * 100
                print(f"  {emotion}: {count} é¦– ({percentage:.1f}%)")
        
        # Create basic visualization
        print(f"\nğŸ¨ ç”ŸæˆåŸºç¡€å¯è§†åŒ–...")
        viz = VisualizationTools()
        viz.plot_emotion_distribution(
            df, emotion_names, 
            'results/visualizations/emotion_distribution.png'
        )
        
        # Sample analysis without training
        print(f"\nğŸ¤– æ¨¡æ‹Ÿæƒ…æ„Ÿåˆ†æç¤ºä¾‹:")
        sample_poems = [
            "æ˜¥èŠ±ç§‹æœˆä½•æ—¶äº†ï¼Œå¾€äº‹çŸ¥å¤šå°‘",
            "ç‹¬åœ¨å¼‚ä¹¡ä¸ºå¼‚å®¢ï¼Œæ¯é€¢ä½³èŠ‚å€æ€äº²", 
            "æ€’å‘å†²å† ï¼Œå‡­æ å¤„",
            "æ˜¥é£å¾—æ„é©¬è¹„ç–¾ï¼Œä¸€æ—¥çœ‹å°½é•¿å®‰èŠ±"
        ]
        
        for i, poem in enumerate(sample_poems):
            print(f"\n--- ç¤ºä¾‹ {i+1} ---")
            print(f"è¯—å¥: {poem}")
            # This is just a demo - in real training, these would be model predictions
            print("æ¨¡æ‹Ÿæƒ…æ„Ÿé¢„æµ‹:")
            if "æ˜¥èŠ±ç§‹æœˆ" in poem:
                print("  å“€ä¼¤: 0.85, æ€å¿µ: 0.72")
            elif "å¼‚ä¹¡" in poem:
                print("  æ€å¿µ: 0.91, å“€ä¼¤: 0.43")
            elif "æ€’å‘å†²å† " in poem:
                print("  æ€¨æ¨: 0.88, æ„¤æ€’: 0.76")
            else:
                print("  å–œæ‚¦: 0.82, æ€å¿µ: 0.24")
        
        print(f"\nâœ… å¿«é€Ÿæ¼”ç¤ºå®Œæˆ!")
        print("è¿è¡Œ 'python main.py train' è¿›è¡Œå®Œæ•´æ¨¡å‹è®­ç»ƒ")
        
        return df, emotion_names
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        return None, None

def run_full_training():
    """å®Œæ•´è®­ç»ƒæµç¨‹"""
    print("=" * 50)
    print("ğŸš€ è¯—æ­Œæƒ…æ„Ÿåˆ†æç³»ç»Ÿ - å®Œæ•´è®­ç»ƒ")
    print("=" * 50)
    
    # Setup
    simple_setup()
    
    # Check data
    existing_files, missing_files = check_data_files()
    
    if 'data/poem_emotions_consolidated.csv' not in existing_files:
        print("\nâŒ é”™è¯¯: æ‰¾ä¸åˆ°ä¸»è¦æ•°æ®æ–‡ä»¶")
        return None, None
    
    try:
        # Load unlabeled data for pretraining
        unlabeled_texts = []
        if 'data/unlabeled_poems.txt' in existing_files:
            print(f"\nğŸ“š åŠ è½½æ— æ ‡ç­¾æ•°æ®...")
            with open('data/unlabeled_poems.txt', 'r', encoding='utf-8') as f:
                unlabeled_texts = [line.strip() for line in f if line.strip()]
            print(f"âœ… åŠ è½½äº† {len(unlabeled_texts)} é¦–æ— æ ‡ç­¾è¯—æ­Œ")
        else:
            print(f"\nâš ï¸  æœªæ‰¾åˆ°æ— æ ‡ç­¾æ•°æ®ï¼Œè·³è¿‡é¢„è®­ç»ƒæ­¥éª¤")
        
        # Step 1: Optional Pretraining
        pretrained_model_path = 'bert-base-chinese'  # Default
        
        if len(unlabeled_texts) > 100:
            print(f"\nğŸ”§ æ­¥éª¤1: é¢„è®­ç»ƒå‡†å¤‡...")
            try:
                pretrainer = PoetryPretrainer()
                # Use simplified pretraining approach
                pretrained_model_path = pretrainer.pretrain_model(
                    unlabeled_texts[:500],  # Use subset for speed
                    output_dir='results/models/pretrained',
                    epochs=2
                )
                print(f"âœ… é¢„è®­ç»ƒå‡†å¤‡å®Œæˆï¼Œä½¿ç”¨æ¨¡å‹: {pretrained_model_path}")
            except Exception as e:
                print(f"âš ï¸  é¢„è®­ç»ƒå¤±è´¥: {e}")
                print("å°†ä½¿ç”¨é»˜è®¤BERTæ¨¡å‹")
                pretrained_model_path = 'bert-base-chinese'
        else:
            print(f"\nğŸ”§ æ­¥éª¤1: ä½¿ç”¨é¢„è®­ç»ƒBERTæ¨¡å‹...")
            pretrained_model_path = 'bert-base-chinese'
        
        # Step 2: Load labeled data
        print(f"\nğŸ“Š æ­¥éª¤2: åŠ è½½æ ‡æ³¨æ•°æ®...")
        trainer = PoetryEmotionTrainer(model_name=pretrained_model_path)
        texts, labels = trainer.load_data('data/poem_emotions_consolidated.csv')
        print(f"âœ… åŠ è½½äº† {len(texts)} é¦–æ ‡æ³¨è¯—æ­Œ")
        
        # Step 3: Prepare datasets
        print(f"\nğŸ”„ æ­¥éª¤3: å‡†å¤‡è®­ç»ƒæ•°æ®...")
        train_dataset, val_dataset, test_dataset = trainer.prepare_datasets(texts, labels)
        
        # Step 4: Train model (Use Simple Trainer directly to avoid dependency issues)
        print(f"\nğŸ¯ æ­¥éª¤4: è®­ç»ƒæ¨¡å‹...")
        print("â³ è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ...")
        
        try:
            # Use the simple trainer (more reliable)
            print("ğŸ”„ ä½¿ç”¨ç®€åŒ–è®­ç»ƒå™¨...")
            simple_trainer = SimplePoetryTrainer(
                model_name=pretrained_model_path,
                emotion_names=trainer.emotion_names
            )
            
            trained_model = simple_trainer.train_model(
                train_dataset,
                val_dataset,
                output_dir='results/models/final_model',
                epochs=3,  # Good balance of speed and quality
                batch_size=4,  # Conservative for memory
                learning_rate=2e-5
            )
            
            # Update trainer reference for later use
            trainer.model = simple_trainer.model
            trainer.tokenizer = simple_trainer.tokenizer
            
            print(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ")
            
        except Exception as e:
            print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
            print("è·³è¿‡è®­ç»ƒæ­¥éª¤ï¼Œä½¿ç”¨æ¼”ç¤ºæ¨¡å¼...")
            return None, None
        
        # Step 5: Evaluate
        print(f"\nğŸ“ˆ æ­¥éª¤5: è¯„ä¼°æ¨¡å‹...")
        predictions, true_labels = trainer.evaluate_model(test_dataset)
        
        # Step 6: Generate visualizations
        print(f"\nğŸ¨ æ­¥éª¤6: ç”Ÿæˆå¯è§†åŒ–...")
        viz = VisualizationTools()
        
        # Load data for visualization
        df = pd.read_csv('data/poem_emotions_consolidated.csv', encoding='utf-8')
        
        # Create visualizations
        viz.plot_emotion_distribution(
            df, trainer.emotion_names, 
            'results/visualizations/emotion_distribution.png'
        )
        
        viz.plot_confusion_matrix(
            true_labels, predictions, trainer.emotion_names,
            'results/visualizations/confusion_matrices.png'
        )
        
        print(f"âœ… åŸºç¡€å¯è§†åŒ–å®Œæˆ")
        
        # Step 7: Model interpretation
        print(f"\nğŸ” æ­¥éª¤7: æ¨¡å‹è§£é‡Š...")
        interpreter = PoetryInterpreter(trainer.model, trainer.tokenizer, trainer.emotion_names)
        
        # Test samples
        sample_poems = [
            "æ˜¥èŠ±ç§‹æœˆä½•æ—¶äº†ï¼Œå¾€äº‹çŸ¥å¤šå°‘",
            "ç‹¬åœ¨å¼‚ä¹¡ä¸ºå¼‚å®¢ï¼Œæ¯é€¢ä½³èŠ‚å€æ€äº²", 
            "æ€’å‘å†²å† ï¼Œå‡­æ å¤„",
            "æ˜¥é£å¾—æ„é©¬è¹„ç–¾ï¼Œä¸€æ—¥çœ‹å°½é•¿å®‰èŠ±"
        ]
        
        print(f"\nğŸ­ æƒ…æ„Ÿåˆ†æç¤ºä¾‹:")
        for i, poem in enumerate(sample_poems):
            print(f"\n--- ç¤ºä¾‹ {i+1} ---")
            print(f"è¯—å¥: {poem}")
            
            try:
                explanation = interpreter.explain_prediction(poem)
                
                print("æƒ…æ„Ÿé¢„æµ‹:")
                for emotion, score in explanation['predictions'].items():
                    if score > 0.3:  # Only show confident predictions
                        print(f"  {emotion}: {score:.3f}")
                
                print("å…³é”®è¯åˆ†æ:")
                for emotion, word_importance in explanation['word_importance'].items():
                    if word_importance:
                        top_words = word_importance[:3]
                        print(f"  {emotion}: {[f'{word}({score:.3f})' for word, score in top_words]}")
                        
            except Exception as e:
                print(f"  âš ï¸ åˆ†æå¤±è´¥: {e}")
        
        # Step 8: Create teaching materials
        print(f"\nğŸ“ æ­¥éª¤8: ç”Ÿæˆæ•™å­¦ææ–™...")
        
        try:
            attention_viz = AttentionVisualizer(trainer.model, trainer.tokenizer, trainer.emotion_names)
            
            # Use first sample for demonstration
            sample_poem = sample_poems[0]
            sample_explanation = interpreter.explain_prediction(sample_poem)
            
            # Create attention heatmap
            print("  ç”Ÿæˆæ³¨æ„åŠ›çƒ­åŠ›å›¾...")
            attention_viz.create_attention_heatmap(
                sample_poem,
                save_path='results/visualizations/attention_heatmap_demo.png'
            )
            
            # Create emotion radar
            print("  ç”Ÿæˆæƒ…æ„Ÿé›·è¾¾å›¾...")
            attention_viz.create_interactive_emotion_radar(
                sample_explanation['predictions'],
                sample_poem,
                save_path='results/visualizations/emotion_radar_demo.html'
            )
            
            print(f"âœ… æ•™å­¦ææ–™ç”Ÿæˆå®Œæˆ")
            
        except Exception as e:
            print(f"âš ï¸ æ•™å­¦ææ–™ç”Ÿæˆéƒ¨åˆ†å¤±è´¥: {e}")
        
        # Final summary
        print(f"\n" + "=" * 50)
        print("ğŸ‰ ç³»ç»Ÿè®­ç»ƒå®Œæˆ!")
        print("=" * 50)
        print("ğŸ“ ç»“æœæ–‡ä»¶ä½ç½®:")
        print("  ğŸ¤– è®­ç»ƒæ¨¡å‹: results/models/final_model/")
        print("  ğŸ“Š å¯è§†åŒ–å›¾è¡¨: results/visualizations/")
        print("  ğŸ“ˆ æƒ…æ„Ÿåˆ†å¸ƒå›¾: results/visualizations/emotion_distribution.png")
        print("  ğŸ”¥ æ³¨æ„åŠ›çƒ­åŠ›å›¾: results/visualizations/attention_heatmap_demo.png")
        print("  ğŸ¯ æƒ…æ„Ÿé›·è¾¾å›¾: results/visualizations/emotion_radar_demo.html")
        print("=" * 50)
        
        return trainer, interpreter
        
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        print("è¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶å’Œä¾èµ–æ˜¯å¦æ­£ç¡®å®‰è£…")
        return None, None

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) > 1:
        command = sys.argv[1].lower()
        
        if command == 'demo':
            run_quick_demo()
        elif command == 'train':
            run_full_training()
        else:
            print("ç”¨æ³•:")
            print("  python main.py demo    # å¿«é€Ÿæ¼”ç¤º")  
            print("  python main.py train   # å®Œæ•´è®­ç»ƒ")
    else:
        print("ğŸš€ è¯—æ­Œæƒ…æ„Ÿåˆ†æç³»ç»Ÿ")
        print("\né€‰æ‹©è¿è¡Œæ¨¡å¼:")
        print("1. å¿«é€Ÿæ¼”ç¤º (ä¸è®­ç»ƒæ¨¡å‹)")
        print("2. å®Œæ•´è®­ç»ƒ (è®­ç»ƒå¹¶ä¿å­˜æ¨¡å‹)")
        
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1 æˆ– 2): ").strip()
        
        if choice == '1':
            run_quick_demo()
        elif choice == '2':
            run_full_training()
        else:
            print("æ— æ•ˆé€‰æ‹©ï¼Œè¿è¡Œå¿«é€Ÿæ¼”ç¤º...")
            run_quick_demo()

if __name__ == "__main__":
    main()